{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921cc311",
   "metadata": {},
   "source": [
    "1 Fetch the Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c617c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.treasury.gov.lk/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "print(response.status_code)  # 200 means successful\n",
    "html_content = response.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838bb83f",
   "metadata": {},
   "source": [
    "This code:\n",
    "\n",
    "Connects to the Ministry of Finance website.\n",
    "\n",
    "Checks if the connection is successful.\n",
    "\n",
    "Saves the website’s HTML code for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15326948",
   "metadata": {},
   "source": [
    "Parse HTML Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8f38fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-X5XT78QC7P\">\n",
      "  </script>\n",
      "  <script>\n",
      "   window.dataLayer = window.dataLayer || [];\n",
      "            function gtag(){dataLayer.push(arguments);}\n",
      "            gtag('js', new Date());\n",
      "            gtag('config', 'G-X5XT78QC7P', {\n",
      "              page_path: window.location.pathname,\n",
      "            });\n",
      "  </script>\n",
      "  <meta content=\"width=device-width\" name=\"viewport\"/>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <link href=\"https://fonts.googleapis.com/css2?family=Raleway:wght@400;500;700;900&amp;display=swap\" rel=\"stylesheet\"/>\n",
      "  <title>\n",
      "   Ministry of Finance - Sri lanka\n",
      "  </title>\n",
      "  <link href=\"/favicon.ico\" rel=\"icon\"/>\n",
      "  <link as=\"style\" href=\"/_next/static/css/32c251979959008ca97b.css\" rel=\"preload\"/>\n",
      "  <link data-n-g=\"\" href=\"/_next/static/css/32c251979959008ca97b.css\" rel=\"stylesheet\"/>\n",
      "  <link as=\"style\" href=\"/_next/static/css/a1dd6b1741da6116c21d.css\" rel=\"preload\"/>\n",
      "  <link data-n-p=\"\" href=\"/_next/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Optional: print the first 1000 characters to inspect\n",
    "print(soup.prettify()[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be54aff",
   "metadata": {},
   "source": [
    "This second code:\n",
    "\n",
    "Takes the HTML from the website.\n",
    "\n",
    "Converts it into a structured format that’s easy to work with.\n",
    "\n",
    "Prints the first part of it so you can visually confirm the page content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029c0ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 tables\n",
      "Table 0\n",
      "  Currency     Buying    Selling\n",
      "0      USD  298.86LKR  306.09LKR\n",
      "1      GBP  401.01LKR  413.27LKR\n",
      "Table 1\n",
      "                    Unnamed: 0   Year / Month Amount / LKR Bn\n",
      "0  Governement Revenue & Grant  Jan-July 2024          2155.9\n",
      "1       Government Expenditure  Jan-July 2024          3034.4\n",
      "2       Overall Budget Deficit              .               .\n",
      "Table 2\n",
      "   #               Item   Pettah Dambulla\n",
      "0  1              Samba  0LKR/Kg  0LKR/Kg\n",
      "1  2  Red-Onions(Local)  0LKR/Kg  0LKR/Kg\n",
      "Table 3\n",
      "     Month/Year  Export  Import  Trade Balance\n",
      "0  Jan-Nov 2023       0       0              0\n",
      "1  Jan-Nov 2022       0       0              0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.treasury.gov.lk\"  # replace with actual table page\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "print(f\"Found {len(tables)} tables\")\n",
    "for i, table in enumerate(tables):\n",
    "    print(f\"Table {i}\")\n",
    "    print(table.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee0856",
   "metadata": {},
   "source": [
    "This code:\n",
    "\n",
    "Opens the Treasury webpage.\n",
    "\n",
    "Finds all <table> elements automatically.\n",
    "\n",
    "Saves each table into a DataFrame.\n",
    "\n",
    "Displays them one by one.\n",
    "\n",
    "It’s a shortcut compared to using BeautifulSoup, because Pandas does the heavy lifting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f2efc",
   "metadata": {},
   "source": [
    "How many Raws in the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149bea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "resp = requests.get(\"https://www.treasury.gov.lk\")\n",
    "tree = html.fromstring(resp.content)\n",
    "\n",
    "# Extract all table rows with XPath\n",
    "rows = tree.xpath(\"//table//tr\")\n",
    "print(len(rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921647c",
   "metadata": {},
   "source": [
    "This code:\n",
    "\n",
    "Connects to the Treasury site.\n",
    "\n",
    "Parses the HTML with lxml.\n",
    "\n",
    "Counts how many rows exist in all tables combined.\n",
    "\n",
    "It’s like asking: “How many rows of data are on this website’s tables?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59e70a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.11.1)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (23.10.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (43.0.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (1.8.1)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (24.2.1)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (2.1.2)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (5.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (75.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (24.1)\n",
      "Requirement already satisfied: tldextract in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (5.1.2)\n",
      "Requirement already satisfied: lxml>=4.4.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (5.2.1)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->scrapy) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->scrapy) (2.21)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda3\\lib\\site-packages (from protego>=0.1.15->scrapy) (1.16.0)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (25.3.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\dell\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: automat>=0.8.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (23.10.4)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: incremental>=22.10.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=18.9.0->scrapy) (3.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.32.3)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13a86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50567673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 tables\n",
      "\n",
      "Table 0\n",
      "  Currency     Buying    Selling\n",
      "0      USD  298.86LKR  306.09LKR\n",
      "1      GBP  401.01LKR  413.27LKR\n",
      "\n",
      "Table 1\n",
      "                    Unnamed: 0   Year / Month Amount / LKR Bn\n",
      "0  Governement Revenue & Grant  Jan-July 2024          2155.9\n",
      "1       Government Expenditure  Jan-July 2024          3034.4\n",
      "2       Overall Budget Deficit              .               .\n",
      "\n",
      "Table 2\n",
      "   #               Item   Pettah Dambulla\n",
      "0  1              Samba  0LKR/Kg  0LKR/Kg\n",
      "1  2  Red-Onions(Local)  0LKR/Kg  0LKR/Kg\n",
      "\n",
      "Table 3\n",
      "     Month/Year  Export  Import  Trade Balance\n",
      "0  Jan-Nov 2023       0       0              0\n",
      "1  Jan-Nov 2022       0       0              0\n",
      "\n",
      "Found 96 links\n",
      "First 10 links: ['#home', '#budget-highlights', '#at-a-glance', '#mof-links', '/', '/si/#', '/ta/#', '/#', '/search', '/']\n",
      "\n",
      "Budget Highlights Section:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE = \"https://www.treasury.gov.lk\"\n",
    "\n",
    "# Part A: Extract all tables\n",
    "tables = pd.read_html(BASE)\n",
    "print(f\"Found {len(tables)} tables\")\n",
    "for i, t in enumerate(tables):\n",
    "    print(f\"\\nTable {i}\")\n",
    "    print(t.head())\n",
    "\n",
    "# Save to Excel\n",
    "with pd.ExcelWriter(\"treasury_tables.xlsx\") as w:\n",
    "    for i, t in enumerate(tables):\n",
    "        t.to_excel(w, sheet_name=f\"table_{i}\", index=False)\n",
    "\n",
    "# Part B: Extract all links\n",
    "resp = requests.get(BASE)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "links = [a[\"href\"] for a in soup.find_all(\"a\", href=True)]\n",
    "\n",
    "print(f\"\\nFound {len(links)} links\")\n",
    "print(\"First 10 links:\", links[:10])\n",
    "\n",
    "pd.Series(links, name=\"links\").to_csv(\"homepage_links.csv\", index=False)\n",
    "\n",
    "# Part C: Budget Highlights text\n",
    "budget = soup.find(id=\"budget-highlights\")\n",
    "if budget:\n",
    "    print(\"\\nBudget Highlights Section:\")\n",
    "    print(budget.get_text(strip=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d52e91",
   "metadata": {},
   "source": [
    "his code:\n",
    "\n",
    "Extracts all tables from the Treasury homepage.\n",
    "\n",
    "Saves them neatly into an Excel file.\n",
    "\n",
    "Extracts all links (like menus, resources, PDFs).\n",
    "\n",
    "Saves them into a CSV file.\n",
    "\n",
    "So you’ve got structured data (tables) and navigation data (links) — both stored in reusable files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b9293",
   "metadata": {},
   "source": [
    "Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75807c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page title: Ministry of Finance - Sri lanka\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.treasury.gov.lk\"\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "print(\"Page title:\", soup.title.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee86c1",
   "metadata": {},
   "source": [
    "This code:\n",
    "\n",
    "Connects to the Treasury website.\n",
    "\n",
    "Parses the HTML with BeautifulSoup.\n",
    "\n",
    "Extracts just the title of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51004819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: ['/assets/images/main-bannerlogo.png', '/assets/icons/search/searchblue.png', '/assets/icons/search/searchwhite.png', '/assets/icons/hamburger.svg', 'data:image/svg+xml;charset=utf-8,<svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"/>', 'data:image/svg+xml;charset=utf-8,<svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"/>', 'data:image/svg+xml;charset=utf-8,<svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"/>', 'data:image/svg+xml;charset=utf-8,<svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"/>', 'data:image/svg+xml;charset=utf-8,<svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"/>', 'data:image/svg+xml;charset=utf-8,<svg width=\"20\" height=\"20\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\"/>']\n"
     ]
    }
   ],
   "source": [
    "images = [img[\"src\"] for img in soup.find_all(\"img\", src=True)]\n",
    "print(\"Images:\", images[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a447d3",
   "metadata": {},
   "source": [
    "This code:\n",
    "\n",
    "Finds all image elements (<img>) on the page.\n",
    "\n",
    "Collects their source file paths (like .png, .jpg, .svg).\n",
    "\n",
    "Shows you the first 10 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8626644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\dell\\anaconda3\\lib\\site-packages (10.4.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pytesseract in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "pip install pillow pytesseract requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8784ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.34.2)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\dell\\anaconda3\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: urllib3~=2.5.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (2025.8.3)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dell\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527d78d",
   "metadata": {},
   "source": [
    "Selenium Screenshot Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dac107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screenshot saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "URL = \"https://www.treasury.gov.lk\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--window-size=1400,1600\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "try:\n",
    "    driver.get(URL)\n",
    "    time.sleep(2)  # wait a bit\n",
    "    driver.save_screenshot(\"treasury_test.png\")\n",
    "    print(\"Screenshot saved successfully.\")\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b48b3a3",
   "metadata": {},
   "source": [
    "In Simple Words\n",
    "\n",
    "This code:\n",
    "\n",
    "Opens the Ministry of Finance website in Chrome.\n",
    "\n",
    "Waits a little for it to load.\n",
    "\n",
    "Captures a screenshot of the page.\n",
    "\n",
    "Saves it to your computer.\n",
    "\n",
    "Closes the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f0f0b3",
   "metadata": {},
   "source": [
    "OCR Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c4c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- OCR Preview ---\n",
      "\n",
      "So.\n",
      "Co Ministry of Finance, Planning and Economic . ; ()\n",
      "(Fy) ' Boe TA)] English\n",
      "27) Development ene | Sudlip | Englis\n",
      "Home | About Us | Ministry and Departments | Acts, Gazettes, Circulars & Guidelines | Newsroom | RTI / Internal Affairs Unit | Contact us\n",
      "e\n",
      "&\n",
      "a\n",
      "=\n",
      "o\n",
      "a=\n",
      "« ®sri Lanka Recorded One of the Most\n",
      "NATIONAL <) : = & yr, ~~ ~~. | ce\n",
      "a ; ie! pg | oh = ; | The ™ “ NS =~ ‘  -_=\n",
      "Stat ts and Treasury\n",
      "Citizen Budget > Remarke. an > Management > Vacancies > Publications >\n",
      "Systems\n",
      "\n",
      "\n",
      "Full OCR text saved -> treasury_ocr.txt\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Make sure path is set if needed\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Open the screenshot\n",
    "img = Image.open(\"treasury_test.png\")\n",
    "\n",
    "# Convert to grayscale + upscale for better OCR\n",
    "gray = img.convert(\"L\")\n",
    "gray = gray.resize((gray.width*2, gray.height*2))\n",
    "\n",
    "# Run OCR\n",
    "text = pytesseract.image_to_string(gray, lang=\"eng\", config=\"--psm 6\")\n",
    "\n",
    "# Preview some text\n",
    "print(\"\\n--- OCR Preview ---\\n\")\n",
    "print(text[:600])  # show first 600 chars\n",
    "\n",
    "# Save to file\n",
    "with open(\"treasury_ocr.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"\\nFull OCR text saved -> treasury_ocr.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b531d5",
   "metadata": {},
   "source": [
    "In Simple Words\n",
    "\n",
    "This code:\n",
    "\n",
    "Opens the screenshot from Selenium.\n",
    "\n",
    "Cleans and enlarges it for clarity.\n",
    "\n",
    "Runs OCR to extract text from the image.\n",
    "\n",
    "Prints a preview and saves the full text into a .txt file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
